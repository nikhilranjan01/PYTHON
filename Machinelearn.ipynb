{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exprement 1 FIND-S ALGORITHM\n",
    "\n",
    "import csv\n",
    "num_attributes = 6\n",
    "a = []\n",
    "print(\"\\n The Given Training Data Set \\n\")\n",
    "with open('C:/Users/craxs/Downloads/trial.csv', 'r') as csvfile:\n",
    " reader = csv.reader(csvfile)\n",
    " for row in reader:\n",
    "  a.append (row)\n",
    "  print(row)\n",
    "print(\"\\n a array is\",a)\n",
    "\n",
    "\n",
    "print(\"\\n The initial value of hypothesis: \")\n",
    "hypothesis = ['0'] * num_attributes\n",
    "print(hypothesis)\n",
    "\n",
    "for j in range(0,num_attributes):\n",
    " hypothesis[j] = a[0][j];\n",
    " print(\"new\", hypothesis)\n",
    "print(\"\\n Find S: Finding a Maximally Specific Hypothesis\\n\")\n",
    "print(\"length of a\", len(a))\n",
    "for i in range(0,len(a)):\n",
    "  if a[i][6]=='Yes':\n",
    "     for j in range(0,num_attributes):\n",
    "       if a[i][j]!=hypothesis[j]:\n",
    "        hypothesis[j]='?'\n",
    "       else :\n",
    "        hypothesis[j]= a[i][j]\n",
    "  print(\" For Training instance No:{0} the hypothesis is\".format(i),hypothesis)\n",
    "\n",
    "\n",
    "print(\"\\n The Maximally Specific Hypothesis for a given Training Examples :\\n\")\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exprement 2 CANDIDATE ELIMINATION ALGORITHM\n",
    "'''Objective: For a given set of training data examples stored in a .csv file, implement and\n",
    "demonstrate the Candidate Elimination Algorithm to output a description of the set of all\n",
    "hypotheses consistent with the training examples.'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('C:/Users/craxs/Downloads/trial (1).csv')\n",
    "print(data)\n",
    "\n",
    "concepts = np.array(data.iloc[:,0:6])\n",
    "\n",
    "target = np.array(data.iloc[:,-1])\n",
    "\n",
    "print(\"target\",target)\n",
    "print(\"length of target is---->\", len(target))\n",
    "\n",
    "print(\"\\n Concepts: \\t\",concepts)\n",
    "print(\"\\n shape of concepts is ----->\",concepts.shape)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    print(\"\\nInitialization of specific_h and genearal_h\")\n",
    "    print(\"\\nSpecific Boundary: \", specific_h)\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    print(\"\\nGeneric Boundary: \",general_h)\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        print(\"\\nInstance\", i+1 , \"is \", h)\n",
    "        if target[i] == \"Yes\":\n",
    "            print(\"Instance is *Positive*\")\n",
    "            for x in range(len(specific_h)):\n",
    "                print(\"************************\")\n",
    "                print(\"positive h(x)\", h[x])\n",
    "                print(\"specific_h(x)\", specific_h[x])\n",
    "                print(\"************************\")\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    specific_h[x] ='?'\n",
    "                    general_h[x][x] ='?'\n",
    "\n",
    "        if target[i] == \"No\":\n",
    "            print(\"Instance is *Negative*\")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(\"Specific Bundary after \", i+1, \"Instance is \", specific_h)\n",
    "        print(\"Generic Boundary after \", i+1, \"Instance is \", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?', '?', '?', '?', '?', '?'])\n",
    "    return specific_h, general_h\n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"Final Specific_h: \", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h: \", g_final, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exprement 3 (PART I)  LINEAR REGRESSION (Age Vs Glucose Level Example)....\n",
    "#In this example, we will understand how to use a regression equation to predict the glucose level for given the age....\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array([43,21,25, 42, 57, 59])\n",
    "y = np.array([99, 65, 79, 75, 87, 81])\n",
    "\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Linear Regression Model\")\n",
    "plt.xlabel(\"Age (x-variable)\")\n",
    "plt.ylabel(\"Glucose Level (y-variable)\")\n",
    "plt.show()\n",
    "\n",
    "size_x = np.size(x)\n",
    "size_y=np.size(y)\n",
    "n=size_x\n",
    "print(\"******************************\")\n",
    "print(\"Size of weight (x-variable) is:\", size_x)\n",
    "print(\"Size of height (y-variable) is:\", size_y)\n",
    "print(\"******************************\")\n",
    "\n",
    "# Sum of x and y vector\n",
    "sum_col1_x = np.sum(x)\n",
    "sum_col2_y = np.sum(y)\n",
    "print(\"\\n******************************\")\n",
    "print(\"sum of x-variable is:\", sum_col1_x)\n",
    "print(\"sum of y-variable is:\", sum_col2_y)\n",
    "print(\"******************************\")\n",
    "\n",
    "\n",
    "# Mean of x and y vector\n",
    "m_x = np.mean(x) # or (sum_x)/size_x\n",
    "m_y = np.mean(y) # or (sum_y)/size_y\n",
    "print(\"\\n________________________________________________________\")\n",
    "print(\"Step 1: Calculate the sum of Column 1 and Column 2\")\n",
    "print(\"*******************************************************\")\n",
    "print(\"mean of x-variable is:\", m_x)\n",
    "print(\"mean of y-variable is:\", m_y)\n",
    "print(\"________________________________________________________\")\n",
    "\n",
    "# Sum of column 3, 4, and 5\n",
    "sum_col3_xy = np.sum(y*x)\n",
    "sum_col4_xx = np.sum(x*x)\n",
    "sum_col5_yy = np.sum(y*y)\n",
    "print(\"\\n__________________________________________________________________\")\n",
    "print(\"Step 2: Calculate the sum of Column 3 , Column 4, and Column 5\")\n",
    "print(\"*******************************************************\")\n",
    "print(\"Sum of column 3 (xy) is:\", sum_col3_xy)\n",
    "print(\"Sum of column 4 (xx) is:\", sum_col4_xx)\n",
    "print(\"Sum of column 5 (yy) is:\", sum_col5_yy)\n",
    "print(\"__________________________________________________________________\")\n",
    "\n",
    "# Calculate regression coefficient b0\n",
    "b0_num=(sum_col2_y*sum_col4_xx)-(sum_col1_x*sum_col3_xy)\n",
    "b0_den= (n*sum_col4_xx)-(sum_col1_x*sum_col1_x)\n",
    "b0=b0_num/b0_den # 494979/7445\n",
    "print(\"\\n 1. First *Estimated* Regression Co-efficient *b0* is: \", b0)\n",
    "\n",
    "\n",
    "# Calculate regression coefficient b1\n",
    "b1_num=(n*sum_col3_xy)-(sum_col1_x*sum_col2_y)\n",
    "b1_den= (n*sum_col4_xx)-(sum_col1_x*sum_col1_x)\n",
    "b1=b1_num/b1_den # 2868/7445\n",
    "print(\"\\n 2. Second *Estimated* Regression Co-efficient *b1* is: \", b1)\n",
    "\n",
    "# Linear Regression Equation\n",
    "y_pred = b0 + b1*x\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_predicted values\", y_pred)\n",
    "print(\"y_actual values\", y)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"value of y at age (x)=20 is\", (b1*20)+b0)\n",
    "\n",
    "# Ploting the actual points\n",
    "plt.scatter(x, y, color = \"m\",\n",
    "               marker = \"o\", s = 30)\n",
    "plt.xlabel(\"Age (x-variable)\")\n",
    "plt.ylabel(\"Glucose Level (y-variable)\")\n",
    "\n",
    "# Ploting the estimated predicted line\n",
    "plt.plot(x, y_pred, color = \"g\")\n",
    "plt.title(\"Scatter-plot of the points along with the estimated regression line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 3 (PART II)LINEAR REGRESSION ON SALARY DATASET...\n",
    "#FOR SALARY PREDICTION BASED ON THE NUMBER OF YEARS WORK EXPERIENCE...\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv('C:/Users/craxs/Downloads/Salary_Data.csv')\n",
    "dataset.head()\n",
    "\n",
    "print(\"dataset is: \\n\", dataset)\n",
    "\n",
    "#DEPENDENT AND INDEPENDENT VARIABLES\n",
    "X = dataset.iloc[:,:-1].values  #independent variable array\n",
    "y = dataset.iloc[:,1].values  #dependent variable vector\n",
    "#X1 = dataset.iloc[:,0].values  #independent variable array\n",
    "print(\"X \\n\", X)\n",
    "print(\"y \\n\", y)\n",
    "#print(\"X1 \\n\", X1)\n",
    "\n",
    "#DATA SPLITTING 70:30 RATIO OR 80:20 RATIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"****************************\")\n",
    "print(\"SHAPE OF X_TRAIN:\", X_train.shape)\n",
    "print(\"SHAPE OF Y_TRAIN:\",y_train.shape)\n",
    "print(\"SHAPE OF X_TEST:\",X_test.shape)\n",
    "print(\"SHAPE OF Y_TEST:\",y_test.shape)\n",
    "print(\"****************************\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Fitting linear regression model into the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train) #actually produces the linear eqn for the data\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"****************************\")\n",
    "print(\"coefficient of linear regression\",regressor.coef_)\n",
    "print(\"intercept of linear regression\",regressor.intercept_)\n",
    "print(\"****************************\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"****************************\")\n",
    "print(\"y_pred value is:\", y_pred)\n",
    "print(\"****************************\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"****************************\")\n",
    "print(\"y_test value is:\", y_test)\n",
    "print(\"****************************\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Visualizing the results\n",
    "\n",
    "#PLOT FOR TRAIN\n",
    "\n",
    "plt.scatter(X_train, y_train, color='red') # plotting the observation line\n",
    "\n",
    "\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # plotting the regression line\n",
    "\n",
    "plt.title(\"Salary vs Experience (*Training set*)\") # stating the title of the graph\n",
    "\n",
    "plt.xlabel(\"Years of experience\") # adding the name of x-axis\n",
    "plt.ylabel(\"Salaries\") # adding the name of y-axis\n",
    "plt.show() # specifies end of graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot for the TEST\n",
    "\n",
    "plt.scatter(X_test, y_test, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # plotting the regression line\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Salary vs Experience (*Testing set*)\")\n",
    "\n",
    "plt.xlabel(\"Years of experience\")\n",
    "plt.ylabel(\"Salaries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exprement 4 (PART I)POLYNOMIAL REGRESSION\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Define x and y\n",
    "x=np.array([1,2,3,4])\n",
    "y=np.array([1, 4, 9, 15])\n",
    "\n",
    "print(\"********************************\")\n",
    "print(\"Independent variable x is \\n:\", x)\n",
    "print(\"Dependent variable y is \\n:\", y)\n",
    "print(\"********************************\")\n",
    "\n",
    "#Declare all the variables\n",
    "n=np.size(x)\n",
    "sum_col1_x=np.sum(x)\n",
    "sum_col2_y=np.sum(y)\n",
    "sum_col3_xy=np.sum(x*y)\n",
    "sum_col4_xx=np.sum(x*x)\n",
    "sum_col5_x3=np.sum(x*x*x)\n",
    "sum_col6_x4=np.sum(x*x*x*x)\n",
    "sum_col7_x2y=np.sum(x*x*y)\n",
    "\n",
    "# Print all the variables\n",
    "print(\"********************************\")\n",
    "print(\"number of rows are:\",n)\n",
    "print(\"sum_col1_x is:\", sum_col1_x)\n",
    "print(\"sum_col2_y is:\", sum_col2_y)\n",
    "print(\"sum_col3_xy is:\", sum_col3_xy)\n",
    "print(\"sum_col4_xx is:\", sum_col4_xx)\n",
    "print(\"sum_col5_x3 is:\", sum_col5_x3)\n",
    "print(\"sum_col6_x6 is:\", sum_col6_x4)\n",
    "print(\"sum_col7_x2y is:\", sum_col7_x2y)\n",
    "print(\"********************************\")\n",
    "\n",
    "# Declare matrix X and Calculate the determinant of matrix X\n",
    "\n",
    "X=np.array([[n, sum_col1_x, sum_col4_xx],\n",
    "            [sum_col1_x, sum_col4_xx, sum_col5_x3],\n",
    "           [sum_col4_xx, sum_col5_x3, sum_col6_x4]])\n",
    "det_X=np.linalg.det(X)\n",
    "\n",
    "print(\"********************************\")\n",
    "print(\"Matrix X is\",X)\n",
    "print(\"shape of matrix X is\", X.shape)\n",
    "print(\"Determinant of matrix X is:\", det_X)\n",
    "print(\"********************************\")\n",
    "\n",
    "# Declare matrix Y\n",
    "Y=np.array([[sum_col2_y],\n",
    "            [sum_col3_xy],\n",
    "          [sum_col7_x2y] ])\n",
    "\n",
    "print(\"********************************\")\n",
    "print(\"Matrix Y is\",Y)\n",
    "print(\"shape of matrix Y is\", Y.shape)\n",
    "print(\"********************************\")\n",
    "\n",
    "#Compute the inverse of matrix X\n",
    "\n",
    "X_inverse=np.linalg.inv(X)\n",
    "print(\"********************************\")\n",
    "print(\"Inverse matrix X is:\",X_inverse)\n",
    "print(\"Shape of inverse matrix is\",X_inverse.shape)\n",
    "print(\"********************************\")\n",
    "\n",
    "#Matrix multiplication between X_inverse and Y\n",
    "\n",
    "A=np.matmul(X_inverse,Y)\n",
    "print(\"********************************\")\n",
    "print(\"Polynomial Co-efficients matrix A is\", A)\n",
    "print(\"shape of matrix A is\", A.shape)\n",
    "print(\"********************************\")\n",
    "\n",
    "#Individual polynomila coefficients\n",
    "a0=A[0]\n",
    "a1=A[1]\n",
    "a2=A[2]\n",
    "print(\"********************************\")\n",
    "print(\"Polynomial co-efficient *a0* is:\", a0)\n",
    "print(\"Polynomial co-efficient *a1* is:\", a1)\n",
    "print(\"Polynomial co-efficient *a2* is:\", a2)\n",
    "print(\"********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exprement 4 (PART II)POLYNOMIAL REGRESSION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "X = np.arange(0, 30)\n",
    "print(\"X is:\", X.shape)\n",
    "X=X.reshape(-1,1)\n",
    "print(\"X is:\", X.shape)\n",
    "y = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70, 75, 88, 81, 87, 95, 100, 108, 135, 151, 160, 169, 179]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Fitting linear regression model into the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train) #actually produces the linear eqn for the data\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"****************************\")\n",
    "print(\"coefficient of linear regression\",regressor.coef_)\n",
    "print(\"intercept of linear regression\",regressor.intercept_)\n",
    "print(\"****************************\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"****************************\")\n",
    "print(\"y_pred value is:\", y_pred)\n",
    "print(\"****************************\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"****************************\")\n",
    "print(\"y_test value is:\", y_test)\n",
    "print(\"****************************\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Visualizing the results\n",
    "\n",
    "#PLOT FOR TRAIN\n",
    "\n",
    "plt.scatter(X_train, y_train, color='red') # plotting the observation line\n",
    "\n",
    "\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # plotting the regression line\n",
    "\n",
    "plt.title(\"Salary vs Experience (*Training set*)\") # stating the title of the graph\n",
    "\n",
    "plt.xlabel(\"Years of experience\") # adding the name of x-axis\n",
    "plt.ylabel(\"Salaries\") # adding the name of y-axis\n",
    "plt.show() # specifies end of graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot for the TEST\n",
    "\n",
    "plt.scatter(X_test, y_test, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # plotting the regression line\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Salary vs Experience (*Testing set*)\")\n",
    "\n",
    "plt.xlabel(\"Years of experience\")\n",
    "plt.ylabel(\"Salaries\")\n",
    "plt.show()\n",
    "\n",
    "#model evaluation\n",
    "\n",
    "print(\"***********************************\")\n",
    "print(\"Mean Absolute Error is:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error is:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error is:\", np.sqrt(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "print(\"***********************************\")\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=1, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(X.reshape(-1, 1))\n",
    "print(poly_features)\n",
    "print(poly_features.shape)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_reg_model = LinearRegression()\n",
    "\n",
    "poly_reg_model.fit(poly_features, y)\n",
    "\n",
    "y_predicted = poly_reg_model.predict(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Experiment 5: KNN Algorithm**\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# np.c_ is the numpy concatenate function\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                      columns= iris['feature_names'] + ['target'])\n",
    "iris_df.head()\n",
    "\n",
    "print(\"******iris['data']******* \\n\",iris['data'])\n",
    "print(\"\\n\")\n",
    "print(\"******iris['feature_names']******* \\n\",iris['feature_names'])\n",
    "print(\"\\n\")\n",
    "print(\"******iris['target']******* \\n\",iris['target'])\n",
    "iris_df.describe()\n",
    "print(\"Iris dataframe first five rows: \\n\", iris_df.head())\n",
    "x= iris_df.iloc[:, :-1]\n",
    "y= iris_df.iloc[:, -1]\n",
    "print(\"*************************\")\n",
    "print(\"first five rows of x are: \\n\",x.head())\n",
    "print(\"\\n\")\n",
    "print(\"first five rows of y are: \\n\",y.head())\n",
    "print(\"*************************\")\n",
    "print(\"*************************\")\n",
    "print(\"LAST five rows of x are: \\n\",x.tail())\n",
    "print(\"\\n\")\n",
    "print(\"LAST five rows of y are: \\n\",y.tail())\n",
    "print(\"*************************\")\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y,test_size= 0.2,shuffle= True,random_state= 0)\n",
    "x_train= np.array(x_train)\n",
    "y_train= np.array(y_train)\n",
    "\n",
    "x_test= np.array(x_test)\n",
    "y_test= np.array(y_test)\n",
    "\n",
    "print(\"x train data is: \\n\",x_train)\n",
    "print(\"y train  data is: \\n\",y_train)\n",
    "\n",
    "print(\"***************\")\n",
    "print(\"shape of x_train is: \", x_train.shape)\n",
    "print(\"shape of y_train is: \", y_train.shape )\n",
    "print(\"***************\")\n",
    "\n",
    "print(\"x test data is: \\n\",x_test)\n",
    "print(\"y test  data is: \\n\",y_test)\n",
    "\n",
    "print(\"***************\")\n",
    "print(\"shape of x_test is: \", x_test.shape)\n",
    "print(\"shape of y_test is: \", y_test.shape )\n",
    "print(\"***************\")\n",
    "\n",
    "print(f'training set size: {x_train.shape[0]} samples \\ntest set size: {x_test.shape[0]} samples')\n",
    "\n",
    "scaler= Normalizer().fit(x_train) # the scaler is fitted to the training set\n",
    "normalized_x_train= scaler.transform(x_train) # the scaler is applied to the training set\n",
    "normalized_x_test= scaler.transform(x_test) # the scaler is applied to the test set\n",
    "\n",
    "print('x train before Normalization')\n",
    "print(x_train[0:5])\n",
    "print('\\nx train after Normalization')\n",
    "print(normalized_x_train[0:5])\n",
    "\n",
    "print('x test before Normalization')\n",
    "print(x_test[0:5])\n",
    "print('\\nx test after Normalization')\n",
    "print(normalized_x_test[0:5])\n",
    "\n",
    "print(\"normalized x_train \\n\", normalized_x_train)\n",
    "print(\"************************\")\n",
    "print(\"normalized x_test \\n\", normalized_x_test) \n",
    "\n",
    "di= {0.0: 'Setosa', 1.0: 'Versicolor', 2.0:'Virginica'} # dictionary\n",
    "\n",
    "before= sns.pairplot(iris_df.replace({'target': di}), hue= 'target')\n",
    "before.fig.suptitle('Pair Plot of the dataset Before normalization', y=1.08)\n",
    "iris_df_2= pd.DataFrame(data= np.c_[normalized_x_train, y_train],\n",
    "                        columns= iris['feature_names'] + ['target'])\n",
    "di= {0.0: 'Setosa', 1.0: 'Versicolor', 2.0: 'Virginica'}\n",
    "after= sns.pairplot(iris_df_2.replace({'target':di}), hue= 'target')\n",
    "after.fig.suptitle('Pair Plot of the dataset After normalization', y=1.08)\n",
    "\n",
    "\n",
    "def distance_ecu(x_train, x_test_point):\n",
    "  distances= []  ## create empty list called distances\n",
    "  print(\"length of x_train is: \", len(x_train))\n",
    "  for row in range(len(x_train)): ## Loop over the rows of x_train\n",
    "      print(\"**********************************\")\n",
    "      print(\"row number: \",row )\n",
    "      current_train_point= x_train[row] #Get them point by point\n",
    "      print(\"current train point is: \\n\", current_train_point)\n",
    "      print(\"current test point is: \\n\", x_test_point)\n",
    "      current_distance= 0 ## initialize the distance by zero\n",
    "\n",
    "      for col in range(len(current_train_point)): ## Loop over the columns of the row\n",
    "          current_distance += (current_train_point[col] - x_test_point[col]) **2\n",
    "          ## Or current_distance = current_distance + (x_train[i] - x_test_point[i])**2\n",
    "      current_distance= np.sqrt(current_distance) \n",
    "      print(\"current distance is: \", current_distance)\n",
    "      print(\"**********************************\")\n",
    "      distances.append(current_distance) ## Append the distances\n",
    "      print(\"distance is: \", distances)\n",
    "      print(\"***********************\\n\")\n",
    "  # Store distances in a dataframe\n",
    "  distances= pd.DataFrame(data=distances,columns=['dist'])\n",
    "  print(\"shape of distances is: \", distances.shape)\n",
    "  return distances\n",
    "\n",
    "def nearest_neighbors(distance_point, K):\n",
    "    print(\"*******step 2**********\")\n",
    "    print(\"value of k is: \", K)\n",
    "\n",
    "    # Sort values using the sort_values function\n",
    "    df_nearest= distance_point.sort_values(by=['dist'], axis=0)\n",
    "    print(\"df_nearest at axis 0\", df_nearest)\n",
    "\n",
    "    ## Take only the first K neighbors\n",
    "    df_nearest= df_nearest[:K]\n",
    "    print(\"df_nearest[:k]\", df_nearest)\n",
    "    return df_nearest\n",
    "def voting(df_nearest, y_train):\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(\"*************step 3*************\")\n",
    "    ## Use the Counter Object to get the labels with K nearest neighbors.\n",
    "    counter_vote= Counter(y_train[df_nearest.index])\n",
    "    print(\"counter_vote value is: \", counter_vote)\n",
    "\n",
    "    y_pred= counter_vote.most_common()[0][0]   # Majority Voting\n",
    "\n",
    "    return y_pred\n",
    "def KNN_from_scratch(x_train, y_train, x_test, K):\n",
    "    y_pred=[] \n",
    "    ## Loop over all the test set and perform the three steps\n",
    "    for x_test_point in x_test:\n",
    "      distance_point  = distance_ecu(x_train, x_test_point)  ## Step 1\n",
    "      df_nearest_point= nearest_neighbors(distance_point, K)  ## Step 2\n",
    "      y_pred_point    = voting(df_nearest_point, y_train) ## Step 3\n",
    "      y_pred.append(y_pred_point)\n",
    "\n",
    "    return y_pred\n",
    "K=3\n",
    "y_pred_scratch= KNN_from_scratch(normalized_x_train, y_train, normalized_x_test, K)\n",
    "print(y_pred_scratch)\n",
    " \n",
    "knn=KNeighborsClassifier(K)\n",
    "knn.fit(normalized_x_train, y_train)\n",
    "y_pred_sklearn= knn.predict(normalized_x_test)\n",
    "print(y_pred_sklearn)\n",
    "\n",
    "print(np.array_equal(y_pred_sklearn, y_pred_scratch))\n",
    "print(f'The accuracy of our implementation is {accuracy_score(y_test, y_pred_scratch)}')\n",
    "print(f'The accuracy of sklearn implementation is {accuracy_score(y_test, y_pred_sklearn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "train_data_m = pd.read_csv(\"C:/Users/craxs/Downloads/playTennis.csv\") #importing the dataset from the disk\n",
    "\n",
    "print(train_data_m) #viewing some row of the dataset\n",
    "\n",
    "print(\"shape of train_data_m\", train_data_m.shape)\n",
    "print(\"number of columns of dataset are: \", train_data_m.shape[1])\n",
    "\n",
    "attributes=train_data_m.shape[1]-1\n",
    "print(\"attributes are: \", attributes)\n",
    "target=1\n",
    "print(\" target are: \", target)\n",
    "\n",
    "attributes_val=train_data_m.iloc[:,0:4]\n",
    "print(\"attributes_val \\n\", attributes_val)\n",
    "print(\"shape of attributes_val\", attributes_val.shape)\n",
    "\n",
    "target_val=train_data_m.iloc[:,-1]\n",
    "print(\"target_val \\n\", target_val)\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "total_yes_target=0\n",
    "total_no_target=0\n",
    "for i in range (0, len(target_val)):\n",
    "  print(target_val[i])\n",
    "  if target_val[i]=='Yes':\n",
    "    total_yes_target=total_yes_target+1\n",
    "  else:\n",
    "    total_no_target=total_no_target+1\n",
    "print(\"total yes target are: \", total_yes_target)\n",
    "print(\"total no target are: \", total_no_target)\n",
    "part_a1=(total_yes_target/(total_yes_target+total_no_target))\n",
    "print(\"part_a1\", part_a1)\n",
    "if (part_a1!=0): \n",
    "  part_a=part_a1*(math.log(part_a1,2))\n",
    "  part_b1=(total_no_target/(total_yes_target+total_no_target))\n",
    "  part_b=part_b1*(math.log(part_b1,2))\n",
    "  entropy_total=-part_a-part_b\n",
    "else:\n",
    "  entropy_total=0\n",
    "print(\"Total entropy\", entropy_total)\n",
    "gain=entropy_total\n",
    "\n",
    "total_gain_columns=[]\n",
    "i=0\n",
    "for i in range (0, attributes): #attributes\n",
    "    gain=entropy_total\n",
    "    entropy=[]\n",
    "    attribute_current=train_data_m.iloc[:,i]\n",
    "    print(\"*******************************\")\n",
    "    print(attribute_current)\n",
    "    unique_val=np.unique(attribute_current)\n",
    "    print(\"unique_val: \", unique_val)\n",
    "    for j in range (0, len(unique_val)):\n",
    "        current_unique_val=unique_val[j]\n",
    "    counts= Counter(attribute_current)\n",
    "    print(counts)\n",
    "    for c in counts.keys():\n",
    "        print(c, \":\", counts[c])\n",
    "        res_list = [k for k, value in enumerate(attribute_current) if value == c]\n",
    "        print(\"****************************\")\n",
    "        print(\"Count of\", c, \"is\", counts[c])\n",
    "        print(\"Index of\", c, \"is\", res_list)\n",
    "        target_new=[]\n",
    "        counter_yes=0\n",
    "        counter_no=0\n",
    "        for r in range (0, len(res_list)):\n",
    "          r1=res_list[r]\n",
    "          #print(\"r1\", r1)\n",
    "          target_current=target_val.iloc[r1]\n",
    "          if target_current=='Yes':\n",
    "            counter_yes=counter_yes+1\n",
    "          else:\n",
    "            counter_no=counter_no+1   \n",
    "\n",
    "\n",
    "          #print(\"target_current\", target_current)\n",
    "          target_new.append(target_current)\n",
    "          counts= Counter(target_new)\n",
    "          print(counts)\n",
    "        print(\"target new\",target_new)\n",
    "        print(\"Total yes:\", counter_yes)\n",
    "        print(\"Total no:\", counter_no)\n",
    "        if counter_yes==counter_no:\n",
    "          if (counter_yes==0) or (counter_no==0):\n",
    "            entropy_current=0\n",
    "          else:\n",
    "            entropy_current=1\n",
    "        elif (counter_yes==0) or (counter_no==0):\n",
    "          entropy_current=0\n",
    "        else:\n",
    "          part_a1=(counter_yes/(counter_yes+counter_no))\n",
    "          print(\"part_a1\", part_a1)\n",
    "          part_a=part_a1*(math.log(part_a1,2))\n",
    "\n",
    "          part_b1=(counter_no/(counter_yes+counter_no))\n",
    "          part_b=part_b1*(math.log(part_b1,2))\n",
    "          entropy_current=-part_a-part_b\n",
    "          print(\"entropy of\", c,\" attribute is: \", entropy_current)\n",
    "        entropy.append(entropy_current)\n",
    "        print(\"****************************\")\n",
    "        print(\"Total entropy\", entropy)\n",
    "        print(len(res_list))\n",
    "        print(len(target_val))\n",
    "        current_gain=(len(res_list)/len(target_val))*entropy_current\n",
    "        print(gain)\n",
    "        print(\"current_gain\", current_gain)\n",
    "        gain=gain-current_gain\n",
    "        print(\" Gain of attribute\", c ,\"is: \", gain)\n",
    "    total_gain_columns.append(gain)\n",
    "print(\"************Total gain*******: \", total_gain_columns)\n",
    "\n",
    "\n",
    "max_gain=max(total_gain_columns)\n",
    "index_max=total_gain_columns.index(max(total_gain_columns))\n",
    "print(\"maximum gain is \", max_gain, \"of *\", index_max, \"* attribute\")\n",
    "\n",
    "# importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/craxs/Downloads/playTennis.csv\")\n",
    "list_of_column_names = list(df.columns)\n",
    "print('List of column names : ',list_of_column_names)\n",
    "\n",
    "attribute_name_max=list_of_column_names[index_max]\n",
    "print(attribute_name_max)\n",
    "\n",
    "attribute_max=train_data_m.iloc[:,index_max]\n",
    "print(attribute_max)\n",
    "print(target_val)\n",
    "\n",
    "unique_val=np.unique(attribute_max)\n",
    "print(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"C:/Users/craxs/Downloads/PlayTennis (1).csv\")\n",
    "\n",
    "#create_array\n",
    "data_new=np.array(data)\n",
    "print(\"DATA in array format is: \\n\", data_new)\n",
    "print(\"Shape of data array is: \\n\", data_new.shape)\n",
    "\n",
    "##################\n",
    "train_data=data_new[:-1,:]\n",
    "print(train_data.shape)\n",
    "##################\n",
    "test_data=data_new[-1]\n",
    "print(\"Test data is: \", test_data)\n",
    "\n",
    "\n",
    "total_yes=sum(train_data[:,-1]==\"Yes\")\n",
    "total_no=sum(train_data[:,-1]==\"No\")\n",
    "print(\"Total Yes are: \", total_yes)\n",
    "print(\"Total No are: \", total_no)\n",
    "\n",
    "a1=0\n",
    "b1=0\n",
    "c1=0\n",
    "d1=0\n",
    "a0=0\n",
    "b0=0\n",
    "c0=0\n",
    "d0=0\n",
    "p_yes=total_yes/(total_yes+total_no)\n",
    "p_no=total_no/(total_yes+total_no)\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "  if (train_data[i,-1]==\"Yes\"):\n",
    "    if (train_data[i,0]==test_data[0]):\n",
    "      a1=a1+1\n",
    "    if (train_data[i,1]==test_data[1]):\n",
    "      b1=b1+1\n",
    "    if (train_data[i,2]==test_data[2]):\n",
    "      c1=c1+1\n",
    "    if (train_data[i,3]==test_data[3]):\n",
    "      d1=d1+1\n",
    "\n",
    "  else:\n",
    "    if (train_data[i,0]==test_data[0]):\n",
    "      a0=a0+1\n",
    "    if (train_data[i,1]==test_data[1]):\n",
    "      b0=b0+1\n",
    "    if (train_data[i,2]==test_data[2]):\n",
    "      c0=c0+1\n",
    "    if (train_data[i,3]==test_data[3]):\n",
    "      d0=d0+1\n",
    "\n",
    "print(\"a1:\", a1)\n",
    "print(\"b1:\", b1)\n",
    "print(\"c1:\", c1)\n",
    "print(\"d1:\", d1)\n",
    "print(\"a0:\", a0)\n",
    "print(\"b0:\", b0)\n",
    "print(\"c0:\", c0)\n",
    "print(\"d0:\", d0)\n",
    "\n",
    "a1_yes=a1/total_yes\n",
    "a0_no=a0/total_no\n",
    "b1_yes=b1/total_yes\n",
    "b0_no=b0/total_no\n",
    "c1_yes=c1/total_yes\n",
    "c0_no=c0/total_no\n",
    "d1_yes=d1/total_yes\n",
    "d0_no=d0/total_no\n",
    "\n",
    "\n",
    "pyes=a1_yes*b1_yes*c1_yes*d1_yes*p_yes\n",
    "pno=a0_no*b0_no*c0_no*d0_no*p_no\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"P(Yes): \", pyes)\n",
    "print(\"P(No): \", pno)\n",
    "print(\"***************************\")\n",
    "\n",
    "\n",
    "final_prob_yes=pyes*100/(pyes+pno)\n",
    "final_prob_no=pno*100/(pyes+pno)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"***************************\")\n",
    "print(\"Percentage of *Yes*: \", final_prob_yes)\n",
    "print(\"Percentage of *No*: \", final_prob_no)\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"\\n\")\n",
    "if (final_prob_yes>final_prob_no):\n",
    "  print(\"Answer: As 'P(Yes)>P(No)': NaN will be replaced with 'Yes' \")\n",
    "else:\n",
    "  print(\"Answer: As 'P(No)>P(Yes)': NaN will be replaced with 'No' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Classification using Naive Bayes Classifier\n",
    "\n",
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Reading\n",
    "d=pd.read_csv(\"C:/Users/craxs/Downloads/NBdocument.csv\")\n",
    "a=np.array(d)\n",
    "ab=a[:,1:]\n",
    "a1=[]; b1=[]; a2=[]; a3=[];a4=[]; a11=[]; a21=[]; a31=[]; a41=[];b11=[]\n",
    "b=ab\n",
    "\n",
    "# Computaion of Prior Probability\n",
    "ay=sum(b[:,-1]==\"Electrical Engineering\")/ len(b)\n",
    "an=sum(b[:,-1]==\"Computer Science & Engineering\")/len(b)\n",
    "\n",
    "# Computation of Unique Keywords\n",
    "val,col = np.unique(b,return_counts=True)\n",
    "\n",
    "# Total no. of keywords in whole document\n",
    "x=len(val)\n",
    "print('keywords in whole document are=',val,'x=',x)00\n",
    "#Test data\n",
    "print('Test data i.e. any row from dataset')\n",
    "O=ab[4]\n",
    "\n",
    "# Steps for NB Classifier\n",
    "for i in range(len(b)):\n",
    "    if (b[i,-1]==\"Electrical Engineering\"):\n",
    "\n",
    "        # Total no. of words in EE Category\n",
    "        b1.append(len(b[i,:-1])); f12=np.sum(b1); #print('f12=',f12)\n",
    "\n",
    "        # Computation of Conditional Probability for EE category\n",
    "        a1.append(b[i,:]== O[0]); f1=(1+np.sum(a1))/(f12+x)\n",
    "        a2.append(b[i,:]== O[1]); f2=(1+np.sum(a2))/(f12+x)\n",
    "        a3.append(b[i,:]== O[2]); f3=(1+np.sum(a3))/(f12+x)\n",
    "        a4.append(b[i,:]== O[3]); f4=(1+np.sum(a4))/(f12+x)\n",
    "\n",
    "    else:\n",
    "         # Total no. of words in CSE Category\n",
    "        b11.append(len(b[i,:-1])); f121=np.sum(b11); #print('f121=',f121)\n",
    "\n",
    "        # Computation of Conditional Probability for CSE category\n",
    "        a11.append(b[i,:]== O[0]); f11=(1+np.sum(a11))/(f121+x)\n",
    "        a21.append(b[i,:]== O[1]); f21=(1+np.sum(a21))/(f121+x)\n",
    "        a31.append(b[i,:]== O[2]); f31=(1+np.sum(a31))/(f121+x)\n",
    "        a41.append(b[i,:]== O[3]); f41=(1+np.sum(a41))/(f121+x)\n",
    "\n",
    "# Posterior Probaility for EE category\n",
    "p_ee = ay*f1*f2*f3*f4\n",
    "\n",
    "# Posterior Probaility for CSE category\n",
    "p_cse=an*f11*f21*f31*f41\n",
    "     \n",
    "# Final outcome/ Prediction for test document\n",
    "print('\\n p_ee=',p_ee, '\\n P_cse=',p_cse)\n",
    "if(p_ee>p_cse):\n",
    "    print('\\n Document belongs to EE')\n",
    "else:\n",
    "    print('\\n Document belongs to CSE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
